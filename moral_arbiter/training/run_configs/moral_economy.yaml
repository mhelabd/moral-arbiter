# Copyright (c) 2021, salesforce.com, inc.
# All rights reserved.
# SPDX-License-Identifier: BSD-3-Clause
# For full license text, see the LICENSE file in the repo root
# or https://opensource.org/licenses/BSD-3-Clause
#
# YAML configuration for the tag continuous environment
name: 'moral_economy'
# Environment settings
env:
  scenario_name: 'moral_uniform/simple_wood_and_stone'
  moral_theory: 'virtue_ethics'
  agent_morality: 100
  components:
    - Build:
        skill_dist: pareto
        payment_max_skill_multiplier: 3
        build_labor: 10
        payment: 10
    - ContinuousDoubleAuction:
        max_bid_ask: 10
        order_labor: 0.25
        max_num_orders: 5
        order_duration: 50
    - Gather:
        move_labor: 1
        collect_labor: 1
        skill_dist: pareto
    - Steal:
        steal_labor: 1
        skill_dist: pareto
  starting_agent_coin: 10
  n_agents: 4
  world_size: [25, 25]
  episode_length: 1000
  multi_action_mode_agents: true
  multi_action_mode_planner: false
  flatten_observations: true
  flatten_masks: true
  dense_log_frequency: 1
# Trainer settings
trainer:
    num_gpus: 1
    num_workers: 2
    num_envs_per_worker: 2
    train_batch_size: 100 # total batch size used for training per iteration (across all the environments)
    # Other training parameters
    train_batch_size:  4000
    sgd_minibatch_size: 4000
    num_sgd_iter: 1
# Policy network settings
policy: # list all the policies below
    a:
        to_train: True # flag indicating whether the model needs to be trained
        algorithm: "PPO" # algorithm used to train the policy
        vf_loss_coeff: 1 # loss coefficient schedule for the value function loss
        entropy_coeff: 0.05 # loss coefficient schedule for the entropy loss
        gamma: 0.98 # discount factor
        lr: 0.0001 # learning rate
        model:
            type: "fully_connected"
            fc_dims: [256, 256]
            model_ckpt_filepath: "/home/mhelabd/tmp/moral_economy_1/weights"
    p:
      to_train: False # flag indicating whether the model needs to be trained


# Checkpoint saving setting (and W&B logging)
saving:
    model_params_save_freq: 50 # How often (in iterations) to save the model parameters
    basedir: "/home/mhelabd/tmp/" # base folder used for saving
    name: "moral_economy_1_ve"
    tag: "experiments"
